베이지안 최적화(Bayesian Optimization)

베이지안 최적화는 derivative-free 최적화 방법입니다. 이 유형의 최적화를위한 몇 가지 다른 알고리즘이 있지만 수Gaussian Process(with Acquisition Function)에 특별히 관심이있었습니다. 어떤 사람들에게는 위의 Hand-tuning 섹션에서 설명한 방법과 유사 할 수 있습니다. Gaussian Process는 관찰되지 않은 매개 변수에 대한 가정을 하기 위해 이전에 평가 된 매개 변수 세트와 결과 정확도 세트를 사용합니다. 이 정보를 사용하는 Acquisition Function은 다음 매개 변수 세트를 제안합니다.

Gaussian Process

1 Gaussian Processes
Definition 1. A Gaussian Process is a collection of random variables, any finite number of which have (consistent) joint Gaussian distributions.

정의 1. 가우시안 프로세스 (Gaussian Process)는 무작위 변수의 집합이며, 그 중 유한 수는 (일관된) 합동 가우스 분포를 갖는다.

Gaussian Process는 평균 함수 m (x) 및 공분산 함수 k (x, x’)에 의해 완전히 지정된다. 이것은 평균과 공분산이 각각 벡터와 행렬인 가우시안 분포의 자연스러운 일반화이다. 가우시안 분포는 벡터에 대한 것이며, Gaussian Process 는 함수에 대한 것이다. 이를 아래와 같이 쓴다.

 

가우시안 분포로부터 벡터의 개별 확률 변수는 벡터의 위치에 따라 색인된다. GP의 경우, 인덱스 집합의 역할을 하는 인수 x (임의 함수 f (x))이다. 모든 입력 x에 대해 연관된 확률 변수 f (x)가 있다. 이는 확률적 함수 f를 호출한다. 표기법상의 편의를 위해 자연수로 관심있는 x 값을 열거하고 이러한 인덱스를 프로세스의 인덱스 인 것처럼 사용한다. 프로세스의 인덱스를 xi로 혼동하면 안된다. , 우리는 i로 색인하기로 했다.

무한한 차원의 오브젝트로 작업하는 것은 처음엔 다루기 힘들어 보일지 모르지만, 우리가 컴퓨팅에 관심을 갖는 양은 유한 차원의 오브젝트로만 작업해야 한다는 것을 알게되었다. 사실, 프로세스에 대한 질문에 답하는 것은 관련 분포를 사용하여 컴퓨팅하는 것으로 줄어 듭니다. 이것은 가우스 프로세스가 실현 가능한 이유입니다. 예제를 보겠습니다. 다음에 의해 주어진 가우스 프로세스를 고려하십시오.
 

이 과정을 이해하기 위해 함수 f로부터 샘플을 그릴 수 있습니다. 유한 수량으로 만 작업하기 위해, 우리는 별개의 유한 수 n 개의 위치에서 f의 값만을 요구합니다. 그러한 샘플을 어떻게 생성할까? x 값이 주어지면 평균의 벡터와 공분산 행렬을 다음과 같은 식(2)을 사용하여 평가할 수있다. 식(2)는 정규 가우스 분포를 정의합니다.
 

여기서 우리는 프로세스와 분포의 차이점을 명확히 하기 위해 m과 k 대신, mu와 sigma를 사용한다. 이제 이 분포에서 무작위 벡터를 생성 할 수 있다. 이 벡터는 해당하는 x에 대한 함수 값 f (x)를 좌표로 갖습니다.
 

2 Posterior Gaussian Process
이전 섹션에서 우리는 Gaussian Process 를 사용하여 어떻게 분포를 함수로 정의하는지를 봤다. 
이 GP는 베이지안 추론의 prior 로 사용될 것이다. Prior는 학습데이터에 의존하지 않는데, 그러나 분포 함수()의 몇몇 속성을 지정한다.
 
이 섹션의 목표는 학습 데이터에 비추어 prior를 업데이트하는 간단한 규칙을 유도하는 것이다. 다음 섹션의 목표는 데이터에 비추어, prior의 일부 속성에 대해 배우는 것이다. 

posterior을 계산하는 주된 목표 중 하나는 보이지 않는 테스트 케이스에 대한 예측을 하는 데 사용될 수 있다는 것이다. f를 훈련 사례의 알려진 함수값 이라고하고, f* 를 테스트 세트 입력 X*에 대응하는 함수 값의 세트라고 하자. 다시 말하지만, 우리가 관심있는 모든 것에 대한 joint 분포를 작성한다.
 
Mu: 학습 데이터의 평균
Mu*: 테스트 데이터의 평균
Sigma: 학습데이터의 공분산
Sigma*: 학습데이터-테스트데이터 의 공분산
Sigma**: 테스트데이터의 공분산

우리는 훈련 세트 f의 값을 알고 있으므로, 주어진 f에 대한 f*의 조건부 분포에 관심이있다. 이는 다음과 같이 표현된다.
 
이것은 특정 테스트 케이스 세트에 대한 posterior 분포입니다. 대응하는 posterior 과정을 (검사에 의해) 검증 하는 것은 쉽습니다 :
 

여기서, Σ(X, x)는 모든 학습 데이터(X)와 x 사이의 공분산의 벡터이다. 이들은 GP 예측을 위한 중심 방정식입니다. Posterior mean과 공분산에 대해 이 방정식을 조사해 봅시다. Posterior 분산 kD (x, x’)가 prior의 분산 k (x, x)에서 양수 항을 뺀 것과 같음을 주목하라. 학습 입력에 의존한다. 따라서 데이터가 우리에게 몇 가지 추가 정보를 제공했기 때문에 Posterior 분산은 항상 prior분산보다 작습니다.

우리는 하나의 최종 쟁점, 즉 훈련 산출물의 소음에 대처할 필요가 있다. 관측에 잡음이 있다는 것은 많은 회귀 분석에 공통적으로 적용된다. 가장 일반적인 가정은 출력에서 가산적 i.i.d. Gaussian noise를 가정하는 것이다. GP 모델에서 이러한 노이즈는 쉽게 고려됩니다. 그 효과는 모든 f (x)가 노이즈 분산과 동일한 크기로 (잡음이 독립적이라고 가정되기 때문에) 오직 그 자체와의 여분의 공분산을 갖는다는 것입니다.

 
where δii’ = 1 iff i = i' is the Kronecker’s delta.

Kronecker’s delta 에 대한 인덱스는 case i의 식별이다(input xi에 대한 식별이 아니라). 동일한 입력을 가진 여러 사례가 있을 수 있지만 이러한 사례들의 소음은 독립적이라고 가정합니다. 따라서 잡음이 많은 프로세스에 대한 공분산 함수는 sigmal 공분산과 noise 공분산의 합입니다.

이제 우리는 후부 공분산 함수를 69 페이지의 작은 Matlab 예제에 연결하여 후부 프로세스에서 샘플을 그립니다 (그림 2 참조).

이 절에서 우리는 평균 및 공분산 함수를 이용한 간단한 조작이 훈련 데이터에 비추어 'posterior'에 대한 'prior'를 업데이트 할 수있는 방법을 보여주었다.

그러나 우리는 답이없는 몇 가지 질문을 남겼습니다. 우선 우리는 어떻게 평균과 공분산 함수를 구상합니까? 우리는 어떻게 소음 수준을 추정 할 수 있습니까? 이것은 다음 절의 주제입니다.

3 Training a Gaussian Process
이전 섹션에서는 교육 데이터에 비추어 prior 가우스 프로세스를 업데이트하는 방법을 보았습니다. 이는 데이터셋에 대한 충분한 사전 정보를 가진 경우, 직접 사전 평균과 분한 함수를 지정할 수 있어 유용합니다. 그러나 이러한 상세한 사전 정보의 가용성은 기계 학습 응용 프로그램의 일반적인 경우가 아닙니다. 실제로 GP기법을 가치있게 사용하려면, 데이터에 비추어 다른 평균 및 공분산 함수를 선택할 수 있어야합니다. 이 과정을 GP 모델 training이라고합니다.

일반적으로 모호한 prior 정보에 비추어 볼 때 계층적 prior를 사용합니다. 여기서 평균 및 공분산 함수는 하이퍼파라미터로 매개 변수화됩니다. 예를 들어, Eq. (2) :

 
 

이 계층적 사양()의 목적은 모호한 prior 정보를 간단한 방법으로 지정할 수 있게 한다는 것입니다. 예를 들어, 우리는 함수가 2 차 다항식에 가깝다고 믿었지만 다항식이 정확히 무엇인지, 정확히 "닫음-close"이 의미하는 바를 말하지 않았습니다. 실제로 다항식과 데이터 사이의 불일치는 부드러운 함수와 독립적 인 가우스 노이즈이지만, 다시 한번 우리는 두 개의 기여의 크기 길이 스케일l 또는 크기를 정확하게 지정할 필요가 없습니다. 우리는 데이터에 비추어 모든 하이퍼 매개 변수에 대해 추론 할 수 있기를 원합니다.

이렇게하기 위해 우리는 주어진 하이퍼파라미터에 대한 데이터의 확률을 계산합니다. 다행히도 데이터의 분포가 가우스라고 가정하면 다음과 같이 어렵지 않습니다.
 
이 양을 로그 한계 가능성(log marginal likelihood)이라 부릅니다. 우리는 비모수 모델을 다루고 있다는 것을 강조하기 위해 "한계- marginal"라는 용어를 사용합니다. 

우리는 이제 하이퍼파라미터의 값을 찾을 수 있습니다.
이제 쉽게 평가할 수있는 편미분을 기반으로 한계 우도(marginal likelihood)를 최적화하는 하이퍼파라미터의 값을 찾을 수 있습니다.

 

 

Gaussian process가 non-parametric 모델이라는 사실 때문에, marginal likelihood 는 parametric 모델의 경험으로부터 예상되는 것과 다소 다르게 행동합니다. 먼저, 모델이 훈련 데이터를 정확히 맞추는 것이 실제로 매우 쉽다는 점에 유의하십시오. 간단히 노이즈 레벨σ_n^2을 0으로 설정하고 모델은 훈련 포인트와 정확히 일치하는 평균 예측 함수를 생성합니다. 그러나 이것은 한계 우도 (marginal likelihood)를 최적화 할 때 일반적인 동작이 아닙니다. 실제로, Eq.(10) 에서 로그 한계 가능성 (log marginal likelihood)은 세 항으로 구성됩니다. 
첫 번째 항,-1/2 log|Σ| 모델의 복잡성을 측정하고 불이익을 주는 복잡성 패널티(complexity penalty term)입니다. 
두 번째 항는 음 이차 곡선(negative quadratic)이며 데이터 맞춤 측정(data-fit measure)의 역할을합니다 (이는 학습 세트 출력 값 y에 의존하는 유일한 항 임).
세 번째 항는 로그 정규화 항(log normalization term)으로 데이터와는 별개이며 매우 흥미로운 항은 아닙니다. 

GP 모델에서 페널티와 데이터 적합(data-fit) 간의 절충은 자동으로 이루어집니다. 교차 검증과 같은 일부 외부 메소드에 의해 설정되어야하는 가중치 매개 변수가 없습니다. 이는 교육을 단순화하므로 매우 실용적인 기능입니다. 그림 4는 automatic tradeoff가 어떻게 이루어지는 지 보여줍니다.

 

이 섹션에서는 이전의 계층적 사양을 통해 사전 지식을 편리한 방식으로 표현할 수 있는 방법과 marginal likelihood 최적화를 통해 하이퍼파라미터의 값을 배울 수있는 방법을 살펴 보았습니다. 이것은 gradient 기반 최적화를 사용하여 수행 할 수 있습니다. 또한, 우리는 marginal likelihood 가 Occam의 면도기를 자동으로 통합하는 방법을 보았습니다. 이것은 많은 실질적인 중요성을 지니고 있습니다.

[Gaussian Processes in Machine Learning] http://mlg.eng.cam.ac.uk/pub/pdf/Ras04.pdf



Gaussian Process의 배경은 모든 입력 x 에 대해 y = f (x) 를 출력하는 것입니다. 여기서 f는 확률 적 함수입니다. 이 함수는 가우스 분포의 출력을 샘플링합니다. 또한 각 입력 x은 가우스 분포와 관련 있다고 말할 수 있습니다. 어떤 가우스 분포에 대해 각각의 입력 x Gaussian Process가 평균 mu 과 표준 편차 sigma 를 정의했다는 것을 의미합니다.

Gaussian Process는 Multivariate Gaussian Distribution의 일반화입니다. Multivariate Gaussian Distribution는 평균 벡터 및 공분산 행렬에 의해 정의되며, 가우스 프로세스는 평균 함수 및 공분산 함수로 정의됩니다. 기본적으로 함수는 무한 벡터입니다. 또한 Multivariate Gaussian Distribution는 가능한 입력의 discrete number 가 있는 함수(functions with a discrete number of possible inputs)에 대한 Gaussian Process라고 말할 수 있습니다.

평균 벡터와 공분산 행렬로 정의 된 Multivariate Gaussian Distribution 를 확인해 봅시다.
μ=[■(0.0&1.0)]
∑▒〖=[ ■(1.0&0.7@0.7&2.5)〗  ]

우리는 이 분포에서 점 100개를 샘플링하고 산점도를 만들 수 있습니다. 
 
이러한 샘플을 시각화하는 다른 방법으로는 Parallel Coordinates. 이 있습니다.
 
점들을 연결하는 선들은 단지 각 좌표 들간의 가상적인 관계라는 것을 이해해야합니다. random variable # 1과 random variable # 2 사이에는 아무 것도 없습니다.

우리가 샘플의 수를 늘릴 때 흥미로운 일이 발생합니다.

 

이제 우리는 선들이 부드러운 모양을 이룬다는 것을 알 수 있습니다. 이 모양은 두 개의  random variables 사이의 상관 관계를 정의합니다. 중간에 매우 좁은 경우 두 무작위 변수 사이에 음의 상관 관계가 있습니다.

산점도를 사용하면 시각화 할 수 있는 차원의 수에 제한을 받지만 Parallel Coordinates 를 사용하면 더 많은 차원을 추가 할 수 있습니다. 5 개의 random variables를 사용하여 새로운 Multivariate Gaussian Distribution를 정의합시다.

 

변수가 많을수록 함수처럼 보입니다. 치수의 수를 늘릴 수 있고 Multivariate Gaussian Distribution를 시각화 할 수 있습니다. 더 많은 차원을 추가할수록 Gaussian Process에서 샘플링 된 함수 세트처럼 보입니다. 그러나 Gaussian Process의 경우 차원 수는 무한대여야합니다.

Hand-tuning 섹션 (10 개의 hidden유닛에 65 %의 정확도가있는 섹션, 여기선 생략)에서 데이터를 가져옵니다. 이 데이터를 사용하여 Gaussian Process를 훈련시키고 각 점 x 에 대한 평균 및 표준 편차를 예측할 수 있습니다.
 

파란색 영역은 각 점 x 에 대해 95 % 신뢰 구간을 정의합니다. 우리가 관측 된 샘플로부터 더 멀리 갈수록 더 넓은 신뢰 구간이되는 것이 논리적 결론 인 것을 쉽게 알 수 있습니다. 그 반대도 마찬가지입니다. 사람이 다음 매개 변수 세트를 선택하는 데 사용하는 논리와 매우 유사합니다.

플롯에서 관찰 된 데이터 포인트에는 차이가없는 것처럼 보입니다. 사실, 분산은 0이 아니라 단지 아주 작습니다. 왜냐하면 이전 Gaussian Process 구성에서는 대부분의 신경망에 적용 할 수 없는 결정론적 함수로부터 예측을 얻으려고하기 때문입니다. 이를 해결하기 위해 관측된 변수의 노이즈 양을 정의하는 Gaussian Process의 매개 변수를 변경할 수 있습니다. 이 트릭은 덜 확실한 예측뿐만 아니라 관측 된 데이터 포인트를 통과하지 않는 숨겨진 유닛의 수를 의미합니다.

 
Acquisition Function

Acquisition Function은 다음 단계의 매개 변수 집합을 정의합니다. 다음 단계를 위한 최상의 가치를 계산하는 데 도움이 되는 다양한 기능 [1]이 있습니다. 가장 일반적인 것 중 하나가 Expected Improvement(EI)입니다. 두 가지 방법으로 계산할 수 있습니다. 우리가 최소값을 찾으려고 한다면이 공식을 사용할 수 있습니다.
gmin(x) = max(0, ymin - ylowest expected)
ymin 은 관찰된 값 y의 최소값이다.
ylowest expected은 가능한 각 x값과 관련된 신뢰 구간으로부터 가능한 가장 낮은 값.
우리 case의 경우, 우리는 최대값을 찾으려고 노력하고 있습니다. 최대 값에 대한 EI을 식별하는 방식으로 마지막 공식을 변경할 수 있습니다.
gmax(x) = max(0, yhighest expected – ymax)
ymax 은 관찰된 값 y의 최대값이다.
yhighest expected은 가능한 각 x값과 관련된 신뢰 구간으로부터 가능한 가장 높은 값.

Expected Improvement Function에 대한 각 점 x에 대한 출력입니다.
 

GP with EI의 단점
1. 범주 형 변수에는 적합하지 않습니다. 신경망의 경우 활성화 기능의 일종이 될 수 있습니다.
2. GP with EI는 최적의 관찰을 기반으로 새로운 매개 변수 집합을 선택합니다. 신경망은 보통 최종 점수에 영향을 미치는 훈련 과정에서 무작위 (예 : weight initialization, dropout)를 포함합니다. 동일한 매개 변수로 신경 네트워크를 실행하면 다른 점수가 발생할 수 있습니다. 즉, 우리의 최고의 점수는 특정 매개 변수 집합에 대해 운 좋은 결과가 될 수 있습니다.
3. Gaussian Process에 적합한 하이퍼파라미터를 선택하기가 어려울 수 있습니다. Gaussian Process에는 다양한 커널 유형이 있습니다. 또한 간단한 커널을 빌딩 블록으로 사용하여 더 복잡한 커널을 구성 할 수 있습니다.
4. 그것은 hyperparameters의 수가 증가 할 때 더 천천히 작동합니다. 이는 수많은 매개 변수를 다룰 때 문제가됩니다.

출처 및 참고
http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html#bayesian-optimization

봐볼 것
http://mlg.eng.cam.ac.uk/tutorials/06/es.pdf
https://www.robots.ox.ac.uk/~mebden/reports/GPtutorial.pdf?bcsi_scan_f48ea128b316325d=0&bcsi_scan_filename=GPtutorial.pdf

http://sanghyukchun.github.io/99/




